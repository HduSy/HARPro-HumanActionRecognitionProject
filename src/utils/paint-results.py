import matplotlib.pyplot as plt

# 未加注意力
without_attention = None
# 加注意力
with_attention = None
ten = None
twenty = None
thirty = None
forty = None
other = {'val_loss': [0.784504395227645, 0.40700363230270015, 0.28927978836982293, 0.2168375272417165, 0.18946201996556644, 0.15055739810089552, 0.1471310704946518, 0.11536627134372449, 0.10044612743066242, 0.09219997525819658, 0.08536279917851423, 0.08279856490859154, 0.07272135582705298, 0.0877626858364496, 0.08228056517412648, 0.07435861982510975, 0.0675134652466126, 0.06668254133109873, 0.07233137534610157, 0.07618912983436371, 0.0886063732463738, 0.06902254826217345, 0.06756081317247291, 0.08001656496319277, 0.07138156142788533, 0.08889858302250353, 0.0761872258860973], 'val_accuracy': [0.7981744408607483, 0.8640973567962646, 0.8924949169158936, 0.9259634613990784, 0.9320486783981323, 0.9503042697906494, 0.9442190527915955, 0.9553752541542053, 0.9634888172149658, 0.9604462385177612, 0.9645030498504639, 0.9634888172149658, 0.9655172228813171, 0.9624746441841125, 0.9685598611831665, 0.9675456285476685, 0.9746450185775757, 0.9726166129112244, 0.9756592512130737, 0.9665314555168152, 0.9655172228813171, 0.9736308455467224, 0.9726166129112244, 0.9655172228813171, 0.9736308455467224, 0.9665314555168152, 0.9726166129112244], 'loss': [1.355701211864485, 0.7402173044232775, 0.4686322053757372, 0.3709065175522166, 0.27438969760452775, 0.2314994091282394, 0.19126791071159957, 0.15475254540271652, 0.12749311514293282, 0.12201134152880543, 0.1098957783653614, 0.09342504217880501, 0.07881304214012495, 0.075350854929512, 0.062480275999737656, 0.0559447087699057, 0.0558920404209908, 0.04419481082389888, 0.03986073789606839, 0.038108010677585805, 0.042632758401935325, 0.03269335569153275, 0.028436692028043234, 0.03320027218270671, 0.029472369434173067, 0.02721868702345152, 0.019301986212183955], 'accuracy': [0.51243025, 0.74454594, 0.83688486, 0.8779807, 0.90892947, 0.92770165, 0.94089293, 0.9518011, 0.963724, 0.96347034, 0.9670218, 0.9738711, 0.97843736, 0.9794521, 0.98173517, 0.985033, 0.9870624, 0.98883814, 0.9903602, 0.98959917, 0.9901065, 0.9923897, 0.99264336, 0.99213594, 0.99289703, 0.99289703, 0.9956875]}
# {'val_loss': [0.839083323924712, 0.5002312547838302, 0.360387616217078, 0.2889410837915572, 0.2507305258372388, 0.23087361824208913, 0.20432914637328362, 0.21319917178585995, 0.18240516429199644, 0.17075715943017972, 0.18064509955372562, 0.16859032040011288, 0.15940459220725806, 0.1821060619452908, 0.1650425183580391, 0.17141849329434225, 0.16970370983546207, 0.1738680816026556, 0.17816243655651254, 0.17584159544119055, 0.1645469852339159, 0.17359909774274013, 0.18662193923984288, 0.17426127788631737, 0.18415114129587906, 0.16630074908696005, 0.16842041973911234], 'val_accuracy': [0.6865817904472351, 0.7943192720413208, 0.8579823970794678, 0.8795298933982849, 0.9020568132400513, 0.9187071323394775, 0.9167482852935791, 0.9138100147247314, 0.9275220632553101, 0.9363369345664978, 0.9304603338241577, 0.9353575110435486, 0.9402546286582947, 0.9363369345664978, 0.9392752051353455, 0.9402546286582947, 0.9382957816123962, 0.937316358089447, 0.9382957816123962, 0.9402546286582947, 0.9441723823547363, 0.9402546286582947, 0.9412341117858887, 0.9441723823547363, 0.9402546286582947, 0.9422135353088379, 0.947110652923584], 'loss': [1.4022593948478093, 0.7533248118768977, 0.49823670866597947, 0.380739547807234, 0.3250225788626217, 0.26759114872523837, 0.22841339993128926, 0.19676886379485087, 0.183787448999929, 0.16273321027954116, 0.14830015035294625, 0.13603916043381992, 0.13010460800612786, 0.10882327780760444, 0.11190837648953002, 0.09125205497938, 0.0926405837014074, 0.08446165849196056, 0.07644029845147059, 0.06777410419664724, 0.057675812204362936, 0.05870468430975714, 0.06004557753295401, 0.048109328429038374, 0.04408784457276496, 0.03853959360439269, 0.030121657915415004], 'accuracy': [0.48420823, 0.7285994, 0.81714225, 0.8617948, 0.8832498, 0.9064474, 0.9191897, 0.93160534, 0.9335657, 0.94609016, 0.94946635, 0.9543672, 0.9542583, 0.9640601, 0.9632978, 0.97179264, 0.968961, 0.97288173, 0.9754955, 0.97604007, 0.983228, 0.98159444, 0.9825746, 0.9867131, 0.9866042, 0.9886735, 0.99183184]}
best = \
    {'val_loss': [0.4471571915121667, 0.1759075888895031, 0.12390309070163096, 0.1139693998683328, 0.09467886047516233,
                  0.08597961892022675, 0.08711445708116052, 0.09743561677408498, 0.0942662796270135, 0.090607364456754,
                  0.09269467621574673, 0.10417615653660575, 0.10935573373263544, 0.10390799030676177,
                  0.11123523755358436, 0.10997838084380727, 0.0991632902482114, 0.12494036350235066, 0.1268389504129226,
                  0.1548457051774197, 0.13325640092896668, 0.13206848771430837, 0.13018523795159861, 0.124394998873833,
                  0.12113864586326448, 0.12187795417636896, 0.10712950495705666],
     'val_accuracy': [0.868756115436554, 0.9343780875205994, 0.948090136051178, 0.9490695595741272, 0.9569050073623657,
                      0.9618021249771118, 0.9715964794158936, 0.9559255838394165, 0.9676787257194519,
                      0.9706170558929443, 0.9686581492424011, 0.9715964794158936, 0.9696376323699951,
                      0.9666993021965027, 0.9657198786735535, 0.9696376323699951, 0.9764936566352844,
                      0.9647404551506042, 0.9666993021965027, 0.963761031627655, 0.9666993021965027, 0.9676787257194519,
                      0.9745347499847412, 0.963761031627655, 0.9686581492424011, 0.9696376323699951,
                      0.9745347499847412],
     'loss': [1.1237314373962346, 0.35673746490005936, 0.21294082221162264, 0.14952683830814303, 0.11804150311392757,
              0.09307302810305268, 0.07478693838447716, 0.062338724717793184, 0.04988995391451126, 0.03822893251940215,
              0.025722253397009752, 0.021108063793106424, 0.016946216514104852, 0.017184809157314466,
              0.012823900327563571, 0.012535435657975033, 0.016477918346069445, 0.014725454810514245,
              0.020749608272424103, 0.014717095655063949, 0.015084997061708997, 0.019894463060644036,
              0.01361767577416781, 0.023676565339623666, 0.017666799957559497, 0.008524054677216114,
              0.0076268048886192685],
     'accuracy': [0.613374, 0.8827053, 0.92844695, 0.95284253, 0.96155524, 0.9714659, 0.9789806, 0.98301023, 0.98703986,
                  0.99085164, 0.9947724, 0.995208, 0.9974951, 0.9956437, 0.99727726, 0.99716836, 0.9958615, 0.99684167,
                  0.9942278, 0.9961882, 0.9958615, 0.9943367, 0.9957526, 0.9942278, 0.99401003, 0.9986931, 0.99814856]}
# {'val_loss': [0.4395554823818071, 0.21189496566837182, 0.14649426622992812, 0.1282155886226073, 0.12233139351530337, 0.09895487354289965, 0.09882246456677407, 0.09413218935816055, 0.09034136885498853, 0.09472736054193312, 0.09948096083261943, 0.09459420016828182, 0.1021906741290957, 0.10542969689390533, 0.10415010205363533, 0.10202035863797632, 0.10827556129643583, 0.10789247267064396, 0.1071223701387179, 0.11073426782428214, 0.11492795781309174, 0.1181858220768622, 0.11984107885341692, 0.1347280419988982, 0.13527531385696143, 0.12526937235917932, 0.12984436509435382], 'val_accuracy': [0.8693198561668396, 0.9349569082260132, 0.9474309682846069, 0.9578259587287903, 0.9548559784889221, 0.9643599390983582, 0.9673299789428711, 0.9700029492378235, 0.9688149690628052, 0.9667359590530396, 0.9676269888877869, 0.9700029492378235, 0.965844988822937, 0.9670329689979553, 0.9697059988975525, 0.9702999591827393, 0.9702999591827393, 0.9708939790725708, 0.970596969127655, 0.9688149690628052, 0.970596969127655, 0.9688149690628052, 0.9702999591827393, 0.9670329689979553, 0.9694089889526367, 0.9700029492378235, 0.9688149690628052], 'loss': [1.0552818521273073, 0.36846737337782065, 0.19988443391618846, 0.1365745506217216, 0.11189412224041641, 0.10129868505536778, 0.06872142443074826, 0.05439341281888916, 0.04109033151824548, 0.029522759965231293, 0.025011868502197034, 0.021140739154953438, 0.014888009641727137, 0.019094003600952848, 0.015388267167346337, 0.00938820725414769, 0.008139894145005206, 0.005866901582840453, 0.005259727601157698, 0.004052521364197719, 0.0036720159630339666, 0.0032597468566338025, 0.002859575272308343, 0.006140170636330173, 0.006296283178171225, 0.006643102217123409, 0.007348170114878397], 'accuracy': [0.6376536, 0.88706845, 0.93373317, 0.95011705, 0.9606495, 0.96664715, 0.97893506, 0.9856641, 0.9897601, 0.9951726, 0.995904, 0.99648917, 0.9982446, 0.9963429, 0.9970743, 0.998976, 0.9985372, 0.99956113, 0.9992686, 0.99956113, 0.99941486, 0.99970746, 0.99970746, 0.99868345, 0.9982446, 0.99868345, 0.99941486]}
# training and validation loss
loss_values = other['loss']
val_loss_values = other['val_loss']
# 学习率
# lr = other['lr']
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, 'b', label='Training loss')
plt.plot(epochs, val_loss_values, 'g', label='Validation loss')
# plt.plot(epochs, lr, 'y', label='Learning rate')
plt.title('Training and validation loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()
plt.clf()
# training and validation accuracy
acc_values = other['accuracy']
val_acc_values = other['val_accuracy']
plt.plot(epochs, acc_values, 'b', label='Training acc')
plt.plot(epochs, val_acc_values, 'g', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epoch')
plt.ylabel('Acc')
plt.legend()
plt.show()
