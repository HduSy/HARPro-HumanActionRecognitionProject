import matplotlib.pyplot as plt

# 未加注意力
without_attention = None
# 加注意力
with_attention = None
ten = None
twenty = None
thirty = None
forty = None
other = {'val_loss': [0.42561520252241797, 0.2380464854745977, 0.14664388721650073, 0.10790971276896708, 0.08902949058285656, 0.08229849849855865, 0.08158144499307515, 0.07388381204265922, 0.08528640005923625, 0.07481523012116653, 0.08427265276229347, 0.08202207370147649, 0.07329223265946204, 0.08159314722085442, 0.09009714124689606, 0.09146363611436147, 0.0925026559448791, 0.1004255501869026, 0.10671449822613588, 0.10849154379353818, 0.11099476357748646, 0.13935708595361346, 0.14902064691678082, 0.11627768289505794, 0.11944511391215179, 0.1251251468987703, 0.12650267355122133], 'val_accuracy': [0.8442703485488892, 0.9206660389900208, 0.9451518058776855, 0.963761031627655, 0.9706170558929443, 0.9686581492424011, 0.9657198786735535, 0.9745347499847412, 0.9755141735076904, 0.9794319272041321, 0.9725759029388428, 0.9725759029388428, 0.9774730801582336, 0.9774730801582336, 0.973555326461792, 0.9764936566352844, 0.9764936566352844, 0.9745347499847412, 0.9725759029388428, 0.973555326461792, 0.9764936566352844, 0.9666993021965027, 0.9666993021965027, 0.9715964794158936, 0.9666993021965027, 0.9715964794158936, 0.9706170558929443], 'loss': [1.1783514546299, 0.3996104777144908, 0.25537976862116596, 0.17258561127158817, 0.13578825593773666, 0.10338624512589698, 0.07892226994985382, 0.06299830455697328, 0.05397754052479045, 0.04468391439628949, 0.0351915865636708, 0.03333029101100253, 0.02187970418063508, 0.017418321484362696, 0.013432841456288919, 0.014634834156998282, 0.010293576960514585, 0.009110474248517238, 0.008176957883822797, 0.008836587143652555, 0.009255873498230349, 0.014669518387933048, 0.01650157496917354, 0.012937170747818477, 0.015003516692956258, 0.013247001715948952, 0.0148360092591302], 'accuracy': [0.60291874, 0.85972553, 0.91570467, 0.94293183, 0.95208013, 0.96602046, 0.97288173, 0.980941, 0.9848617, 0.9879111, 0.99085164, 0.9909606, 0.9954258, 0.99597037, 0.99727726, 0.9961882, 0.9979307, 0.99825746, 0.9986931, 0.9979307, 0.9978218, 0.99597037, 0.99499017, 0.996406, 0.9955347, 0.9954258, 0.9956437]}
# {'val_loss': [0.839083323924712, 0.5002312547838302, 0.360387616217078, 0.2889410837915572, 0.2507305258372388, 0.23087361824208913, 0.20432914637328362, 0.21319917178585995, 0.18240516429199644, 0.17075715943017972, 0.18064509955372562, 0.16859032040011288, 0.15940459220725806, 0.1821060619452908, 0.1650425183580391, 0.17141849329434225, 0.16970370983546207, 0.1738680816026556, 0.17816243655651254, 0.17584159544119055, 0.1645469852339159, 0.17359909774274013, 0.18662193923984288, 0.17426127788631737, 0.18415114129587906, 0.16630074908696005, 0.16842041973911234], 'val_accuracy': [0.6865817904472351, 0.7943192720413208, 0.8579823970794678, 0.8795298933982849, 0.9020568132400513, 0.9187071323394775, 0.9167482852935791, 0.9138100147247314, 0.9275220632553101, 0.9363369345664978, 0.9304603338241577, 0.9353575110435486, 0.9402546286582947, 0.9363369345664978, 0.9392752051353455, 0.9402546286582947, 0.9382957816123962, 0.937316358089447, 0.9382957816123962, 0.9402546286582947, 0.9441723823547363, 0.9402546286582947, 0.9412341117858887, 0.9441723823547363, 0.9402546286582947, 0.9422135353088379, 0.947110652923584], 'loss': [1.4022593948478093, 0.7533248118768977, 0.49823670866597947, 0.380739547807234, 0.3250225788626217, 0.26759114872523837, 0.22841339993128926, 0.19676886379485087, 0.183787448999929, 0.16273321027954116, 0.14830015035294625, 0.13603916043381992, 0.13010460800612786, 0.10882327780760444, 0.11190837648953002, 0.09125205497938, 0.0926405837014074, 0.08446165849196056, 0.07644029845147059, 0.06777410419664724, 0.057675812204362936, 0.05870468430975714, 0.06004557753295401, 0.048109328429038374, 0.04408784457276496, 0.03853959360439269, 0.030121657915415004], 'accuracy': [0.48420823, 0.7285994, 0.81714225, 0.8617948, 0.8832498, 0.9064474, 0.9191897, 0.93160534, 0.9335657, 0.94609016, 0.94946635, 0.9543672, 0.9542583, 0.9640601, 0.9632978, 0.97179264, 0.968961, 0.97288173, 0.9754955, 0.97604007, 0.983228, 0.98159444, 0.9825746, 0.9867131, 0.9866042, 0.9886735, 0.99183184]}
best = \
    {'val_loss': [0.4471571915121667, 0.1759075888895031, 0.12390309070163096, 0.1139693998683328, 0.09467886047516233,
                  0.08597961892022675, 0.08711445708116052, 0.09743561677408498, 0.0942662796270135, 0.090607364456754,
                  0.09269467621574673, 0.10417615653660575, 0.10935573373263544, 0.10390799030676177,
                  0.11123523755358436, 0.10997838084380727, 0.0991632902482114, 0.12494036350235066, 0.1268389504129226,
                  0.1548457051774197, 0.13325640092896668, 0.13206848771430837, 0.13018523795159861, 0.124394998873833,
                  0.12113864586326448, 0.12187795417636896, 0.10712950495705666],
     'val_accuracy': [0.868756115436554, 0.9343780875205994, 0.948090136051178, 0.9490695595741272, 0.9569050073623657,
                      0.9618021249771118, 0.9715964794158936, 0.9559255838394165, 0.9676787257194519,
                      0.9706170558929443, 0.9686581492424011, 0.9715964794158936, 0.9696376323699951,
                      0.9666993021965027, 0.9657198786735535, 0.9696376323699951, 0.9764936566352844,
                      0.9647404551506042, 0.9666993021965027, 0.963761031627655, 0.9666993021965027, 0.9676787257194519,
                      0.9745347499847412, 0.963761031627655, 0.9686581492424011, 0.9696376323699951,
                      0.9745347499847412],
     'loss': [1.1237314373962346, 0.35673746490005936, 0.21294082221162264, 0.14952683830814303, 0.11804150311392757,
              0.09307302810305268, 0.07478693838447716, 0.062338724717793184, 0.04988995391451126, 0.03822893251940215,
              0.025722253397009752, 0.021108063793106424, 0.016946216514104852, 0.017184809157314466,
              0.012823900327563571, 0.012535435657975033, 0.016477918346069445, 0.014725454810514245,
              0.020749608272424103, 0.014717095655063949, 0.015084997061708997, 0.019894463060644036,
              0.01361767577416781, 0.023676565339623666, 0.017666799957559497, 0.008524054677216114,
              0.0076268048886192685],
     'accuracy': [0.613374, 0.8827053, 0.92844695, 0.95284253, 0.96155524, 0.9714659, 0.9789806, 0.98301023, 0.98703986,
                  0.99085164, 0.9947724, 0.995208, 0.9974951, 0.9956437, 0.99727726, 0.99716836, 0.9958615, 0.99684167,
                  0.9942278, 0.9961882, 0.9958615, 0.9943367, 0.9957526, 0.9942278, 0.99401003, 0.9986931, 0.99814856]}
# {'val_loss': [0.4395554823818071, 0.21189496566837182, 0.14649426622992812, 0.1282155886226073, 0.12233139351530337, 0.09895487354289965, 0.09882246456677407, 0.09413218935816055, 0.09034136885498853, 0.09472736054193312, 0.09948096083261943, 0.09459420016828182, 0.1021906741290957, 0.10542969689390533, 0.10415010205363533, 0.10202035863797632, 0.10827556129643583, 0.10789247267064396, 0.1071223701387179, 0.11073426782428214, 0.11492795781309174, 0.1181858220768622, 0.11984107885341692, 0.1347280419988982, 0.13527531385696143, 0.12526937235917932, 0.12984436509435382], 'val_accuracy': [0.8693198561668396, 0.9349569082260132, 0.9474309682846069, 0.9578259587287903, 0.9548559784889221, 0.9643599390983582, 0.9673299789428711, 0.9700029492378235, 0.9688149690628052, 0.9667359590530396, 0.9676269888877869, 0.9700029492378235, 0.965844988822937, 0.9670329689979553, 0.9697059988975525, 0.9702999591827393, 0.9702999591827393, 0.9708939790725708, 0.970596969127655, 0.9688149690628052, 0.970596969127655, 0.9688149690628052, 0.9702999591827393, 0.9670329689979553, 0.9694089889526367, 0.9700029492378235, 0.9688149690628052], 'loss': [1.0552818521273073, 0.36846737337782065, 0.19988443391618846, 0.1365745506217216, 0.11189412224041641, 0.10129868505536778, 0.06872142443074826, 0.05439341281888916, 0.04109033151824548, 0.029522759965231293, 0.025011868502197034, 0.021140739154953438, 0.014888009641727137, 0.019094003600952848, 0.015388267167346337, 0.00938820725414769, 0.008139894145005206, 0.005866901582840453, 0.005259727601157698, 0.004052521364197719, 0.0036720159630339666, 0.0032597468566338025, 0.002859575272308343, 0.006140170636330173, 0.006296283178171225, 0.006643102217123409, 0.007348170114878397], 'accuracy': [0.6376536, 0.88706845, 0.93373317, 0.95011705, 0.9606495, 0.96664715, 0.97893506, 0.9856641, 0.9897601, 0.9951726, 0.995904, 0.99648917, 0.9982446, 0.9963429, 0.9970743, 0.998976, 0.9985372, 0.99956113, 0.9992686, 0.99956113, 0.99941486, 0.99970746, 0.99970746, 0.99868345, 0.9982446, 0.99868345, 0.99941486]}
# training and validation loss
loss_values = other['loss']
val_loss_values = other['val_loss']
# 学习率
# lr = other['lr']
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, 'b', label='Training loss')
plt.plot(epochs, val_loss_values, 'g', label='Validation loss')
# plt.plot(epochs, lr, 'y', label='Learning rate')
plt.title('Training and validation loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()
plt.clf()
# training and validation accuracy
acc_values = other['accuracy']
val_acc_values = other['val_accuracy']
plt.plot(epochs, acc_values, 'b', label='Training acc')
plt.plot(epochs, val_acc_values, 'g', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epoch')
plt.ylabel('Acc')
plt.legend()
plt.show()
